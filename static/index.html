<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live EMNIST Recognizer</title>
    <style>
        :root {
            --bg-color: #1a1a1a;
            --text-color: #e0e0e0;
            --primary-color: #4a90e2;
            --border-color: #444;
            --card-bg: #2a2a2a;
        }
        body {
            background-color: var(--bg-color);
            color: var(--text-color);
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            text-align: center;
            padding: 20px;
            margin: 0;
        }
        h2, h3 {
            font-weight: 400;
        }
        #canvas-container {
            position: relative;
            display: inline-block;
            border: 2px dashed var(--border-color);
            margin-top: 15px;
        }
        canvas {
            background-color: black;
            cursor: crosshair;
            display: block;
        }
        #final-prediction {
            font-size: 3em;
            font-weight: bold;
            color: var(--primary-color);
            height: 60px;
            line-height: 60px;
            margin: 10px 0;
            letter-spacing: 0.1em;
        }
        #results-container {
            display: flex;
            flex-wrap: wrap;
            justify-content: center;
            gap: 20px;
            margin-top: 20px;
        }
        .result-card {
            background-color: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 8px;
            padding: 15px;
            width: 250px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        .result-card .char-image-container {
            position: relative;
            width: 100px;
            height: 100px;
            background-color: #000;
            border: 1px solid var(--border-color);
            margin-bottom: 10px;
        }
        .result-card .char-image, .result-card .heatmap-overlay {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
        .result-card .heatmap-overlay {
            /* Heatmap is visible by default. */
            opacity: 0.6;
            transition: opacity 0.3s ease-in-out;
        }
        .result-card .char-image-container:hover .heatmap-overlay {
            /* Heatmap becomes transparent on hover to show the original drawing. */
            opacity: 0;
        }
        .prediction-list {
            list-style: none;
            padding: 0;
            width: 100%;
            text-align: left;
        }
        .prediction-list li {
            display: flex;
            justify-content: space-between;
            margin-bottom: 5px;
            font-size: 1.1em;
        }
        .prediction-list .label {
            font-weight: bold;
        }
        .correction-form {
            margin-top: 15px;
            display: flex;
            width: 100%;
            gap: 5px;
        }
        .correction-form input {
            flex-grow: 1;
            padding: 8px;
            border: 1px solid var(--border-color);
            background-color: #333;
            color: var(--text-color);
            border-radius: 4px;
            text-align: center;
            font-size: 16px;
        }
        .correction-form button {
            padding: 8px 12px;
            border: none;
            background-color: var(--primary-color);
            color: white;
            cursor: pointer;
            border-radius: 4px;
        }
    </style>
</head>
<body>

    <h2>Live Alphanumeric Recognition with Grad-CAM</h2>
    <p>Draw multiple letters and numbers below. Prediction is automatic.</p>

    <div id="canvas-container">
        <canvas id="main-canvas" width="800" height="280"></canvas>
    </div>
    <br>
    <button onclick="clearCanvas()">Clear</button>

    <h3 id="status">Predicted String:</h3>
    <div id="final-prediction">[Waiting for drawing]</div>
    
    <div id="results-container"></div>

<script>
    // --- DOM Element References ---
    const canvas = document.getElementById('main-canvas');
    const ctx = canvas.getContext('2d', { willReadFrequently: true });
    const finalPredictionEl = document.getElementById('final-prediction');
    const resultsContainer = document.getElementById('results-container');
    const statusEl = document.getElementById('status');

    // --- State Variables ---
    let isDrawing = false;
    let predictionTimeout; // Used for debouncing the prediction call

    /**
     * Fills the canvas with a black background.
     */
    function initializeCanvas() {
        ctx.fillStyle = 'black';
        ctx.fillRect(0, 0, canvas.width, canvas.height);
    }
    initializeCanvas();

    // --- Core Drawing Logic ---

    /**
     * Gets the user's cursor or touch coordinates relative to the canvas.
     * @param {Event} e - The mouse or touch event.
     * @returns {{x: number, y: number}} The coordinates.
     */
    function getCoords(e) {
        const rect = canvas.getBoundingClientRect();
        const event = e.touches ? e.touches[0] : e;
        return { x: event.clientX - rect.left, y: event.clientY - rect.top };
    }
    
    function startDrawing(e) {
        isDrawing = true;
        const { x, y } = getCoords(e);
        ctx.beginPath();
        ctx.moveTo(x, y);
    }

    function draw(e) {
        if (!isDrawing) return;
        const { x, y } = getCoords(e);
        ctx.strokeStyle = 'white';
        ctx.lineWidth = 12; // Line thickness for better recognition
        ctx.lineCap = 'round';
        ctx.lineJoin = 'round';
        ctx.lineTo(x, y);
        ctx.stroke();
    }

    /**
     * Finalizes the drawing path and triggers the prediction workflow after a delay.
     */
    function stopDrawing() {
        if (!isDrawing) return;
        isDrawing = false;
        ctx.closePath();
        
        // Debounce prediction to avoid firing on every minor mouse movement.
        clearTimeout(predictionTimeout);
        finalPredictionEl.textContent = 'Analyzing...';
        predictionTimeout = setTimeout(runPredictionWorkflow, 500);
    }
    
    // --- Event Listeners for Mouse and Touch ---
    canvas.addEventListener('mousedown', startDrawing);
    canvas.addEventListener('mousemove', draw);
    canvas.addEventListener('mouseup', stopDrawing);
    canvas.addEventListener('mouseleave', stopDrawing);
    
    // Touch events are mapped to their mouse equivalents for mobile support.
    canvas.addEventListener('touchstart', (e) => { e.preventDefault(); startDrawing(e); });
    canvas.addEventListener('touchmove', (e) => { e.preventDefault(); draw(e); });
    canvas.addEventListener('touchend', (e) => { e.preventDefault(); stopDrawing(e); });

    /**
     * Resets the canvas and all result displays to their initial state.
     */
    function clearCanvas() {
        initializeCanvas();
        finalPredictionEl.textContent = '[Waiting for drawing]';
        resultsContainer.innerHTML = '';
        statusEl.textContent = 'Predicted String:';
    }

    /**
     * Implements a flood-fill-like algorithm to find and separate connected pixel groups (characters).
     * @returns {Array<Object>} An array of bounding box objects, sorted by x-coordinate.
     */
    function segmentDrawing() {
        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const { data, width, height } = imageData;
        const visited = new Set(); // Tracks visited pixels to avoid recounting
        const characterBounds = [];

        // Iterate through each pixel to find starting points of new shapes
        for (let i = 0; i < data.length; i += 4) {
            // If a pixel is not black and has not been visited, start a new search
            if (data[i] > 0 && !visited.has(i)) {
                const boundingBox = { minX: width, minY: height, maxX: 0, maxY: 0 };
                const stack = [i]; // Stack for depth-first search of connected pixels
                visited.add(i);

                while (stack.length > 0) {
                    const pixelIndex = stack.pop();
                    const x = (pixelIndex / 4) % width;
                    const y = Math.floor((pixelIndex / 4) / width);

                    // Update the bounding box for the current character
                    boundingBox.minX = Math.min(boundingBox.minX, x);
                    boundingBox.minY = Math.min(boundingBox.minY, y);
                    boundingBox.maxX = Math.max(boundingBox.maxX, x);
                    boundingBox.maxY = Math.max(boundingBox.maxY, y);

                    // Check all 8 neighboring pixels
                    for (let dy = -1; dy <= 1; dy++) {
                        for (let dx = -1; dx <= 1; dx++) {
                            if (dx === 0 && dy === 0) continue;
                            const nx = x + dx;
                            const ny = y + dy;
                            if (nx >= 0 && nx < width && ny >= 0 && ny < height) {
                                const neighborIndex = (ny * width + nx) * 4;
                                // If the neighbor is part of the drawing and not visited, add to stack
                                if (data[neighborIndex] > 0 && !visited.has(neighborIndex)) {
                                    visited.add(neighborIndex);
                                    stack.push(neighborIndex);
                                }
                            }
                        }
                    }
                }
                // Filter out small noise blobs by checking the bounding box size
                if (boundingBox.maxX - boundingBox.minX > 5 && boundingBox.maxY - boundingBox.minY > 5) {
                    characterBounds.push(boundingBox);
                }
            }
        }
        // Sort characters from left to right based on their position
        characterBounds.sort((a, b) => a.minX - b.minX);
        return characterBounds;
    }

    /**
     * Main function to orchestrate the prediction process.
     * Segments the drawing, sends each character to the backend, and displays the results.
     */
    async function runPredictionWorkflow() {
        resultsContainer.innerHTML = '';
        const characterBounds = segmentDrawing();
        
        if (characterBounds.length === 0) {
            finalPredictionEl.textContent = '[Draw something!]';
            return;
        }

        let fullPredictionString = '';
        statusEl.textContent = `Found ${characterBounds.length} character(s). Predicting...`;
        
        // Process each segmented character sequentially
        for (const [index, bound] of characterBounds.entries()) {
            // Create an image blob for the individual character with padding
            const padding = 20;
            const charWidth = bound.maxX - bound.minX + 2 * padding;
            const charHeight = bound.maxY - bound.minY + 2 * padding;

            const charCanvas = document.createElement('canvas');
            charCanvas.width = charWidth;
            charCanvas.height = charHeight;
            const charCtx = charCanvas.getContext('2d');
            
            // Draw the cropped character onto the new, smaller canvas
            charCtx.drawImage(canvas, bound.minX - padding, bound.minY - padding, charWidth, charHeight, 0, 0, charWidth, charHeight);
            
            const blob = await new Promise(resolve => charCanvas.toBlob(resolve, 'image/png'));
            
            // Send the character image to the backend for prediction
            const formData = new FormData();
            formData.append('file', blob, 'char.png');
            
            try {
                const response = await fetch('/predict', { method: 'POST', body: formData });
                const result = await response.json();
                
                if (result.error) {
                    console.error('Prediction API Error:', result.error);
                    fullPredictionString += '?';
                } else {
                    const topPrediction = result.top_predictions[0].label;
                    fullPredictionString += topPrediction;
                    displayResultCard(charCanvas.toDataURL(), result, index);
                }
            } catch (error) {
                console.error('Fetch API Error:', error);
                fullPredictionString += '?';
            }
        }
        statusEl.textContent = 'Predicted String:';
        finalPredictionEl.textContent = fullPredictionString;
    }

    /**
     * Creates and appends a result card to the DOM for a single character.
     * @param {string} charImageBase64 - The base64 encoded image of the character.
     * @param {object} resultData - The prediction data from the API.
     * @param {number} cardId - A unique index for the card.
     */
    function displayResultCard(charImageBase64, resultData, cardId) {
        const card = document.createElement('div');
        card.className = 'result-card';
        card.id = `card-${cardId}`;

        let predictionsHtml = resultData.top_predictions.map(p => `
            <li><span class="label">${p.label}</span> <span class="confidence">${p.confidence}</span></li>
        `).join('');

        card.innerHTML = `
            <div class="char-image-container" title="Hover to see original drawing">
                <img src="${charImageBase64}" class="char-image" alt="Drawn Character">
                <img src="${resultData.heatmap}" class="heatmap-overlay" alt="Prediction Heatmap">
            </div>
            <ul class="prediction-list">${predictionsHtml}</ul>
            <div class="correction-form">
                <input type="text" maxlength="1" placeholder="Correction?">
                <button>Log</button>
            </div>
        `;
        resultsContainer.appendChild(card);
        
        // Add event listener for the correction submission button
        card.querySelector('.correction-form button').addEventListener('click', () => {
            const input = card.querySelector('input');
            const correctLabel = input.value;
            if (correctLabel && correctLabel.length === 1) {
                logCorrection(charImageBase64, correctLabel);
                input.style.backgroundColor = '#2a9d8f'; // Visual feedback for user
                input.value = "Logged!";
            }
        });
    }

    /**
     * Sends the user's correction to the backend to be logged for future model improvement.
     * @param {string} imageBase64 - The base64 encoded image that was misclassified.
     * @param {string} label - The correct label provided by the user.
     */
    async function logCorrection(imageBase64, label) {
        try {
            await fetch('/log_correction', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ image: imageBase64, label: label })
            });
        } catch (error) {
            console.error('Failed to log correction:', error);
        }
    }
</script>

</body>
</html>