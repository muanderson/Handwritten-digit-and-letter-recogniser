# Handwritten digit and letter recogniser

This is an extension of a previous project **[Handwritten digit recogniser](https://github.com/muanderson/Handwritten-digit-recogniser])**. This work has been extended by instead training a new model (deeper CNN architecture) on **[EMNIST dataset](https://www.kaggle.com/datasets/crawford/emnist])**, and updating the input to take multiple digits and letters, returning both predictions and grad-CAM visualisations in real time.

---

## 🚀 Live Demo

You can try out the live application, deployed on Hugging Face Spaces, at the link below. Draw a combination of digits from 0 to 9 and lower/upper case letters, and see the model's prediction in real-time. Note: performance is not 100% accurate, with a model test F1 of approximately 0.87.

**[➡️ Live Demo on Hugging Face Spaces](https://huggingface.co/spaces/muanderson/emnist-recogniser)**

![Demo GIF of the application working](demo.gif)

---

## Features

* **Deep Learning Model:** A Convolutional Neural Network (CNN) built with PyTorch for image classification.
* **Experiment Tracking:** All training and fine-tuning runs are tracked with **MLflow**, logging parameters, metrics, and model artifacts.
* **Robust Training:** K-Fold cross-validation is used to ensure the model is robust and to select the best performing base model.
* **Transfer Learning:** The base model is **fine-tuned** on a small, custom dataset of user-drawn digits to adapt to a specific drawing style.
* **Containerisation:** The entire application is containerised using **Docker**, ensuring a consistent and reproducible environment.
* **Web Application:** A simple web interface built with **Flask** allows users to draw digits and receive predictions.
* **Cloud Deployment:** The final containerised application is deployed on **Hugging Face Spaces** for public access.

---

## 📂 Project Structure

```
/Digit_Recogniser
|
├─── data/
│    └── train/              # Original MNIST training (<https://www.kaggle.com/datasets/hojjatk/mnist-dataset>)
|
├─── my_drawings/
│    └── 0/                  # Custom drawings for fine-tuning
│    └── 1/
│    └── ...
|
├─── models/
│    └── best_model_fold_2.pt    # Best base model saved from training
│    └── fine_tuned_best_model_1.pt     # Final fine-tuned model
|
├─── static/
│    └── index.html          # Frontend for the Flask app
|
├─── mlruns/                   # Folder auto-generated by MLflow to store experiment data
|       
|─── scripts/
│    └── train.py    # Script for training the base model
│    └── fine_tune.py    # Script for fine-tuning on custom data
│    └── engine.py   # The core training/validation loop function
│    └── interact.py   # Flask application for prediction
│    └── model.py    # CNN model definition
│    └── data_loader.py    # PyTorch Dataset/DataLoader classes
|
├─── requirements.txt          # Python dependencies
└─── Dockerfile                # Instructions to build the application container
```
---

## Technologies Used

* **Python**
* **PyTorch:** For building and training the neural network.
* **MLflow:** For experiment tracking and model management.
* **Docker:** For containerising the application.
* **Flask:** For serving the web application and prediction endpoint.
* **Gunicorn:** As the production web server.
* **Hugging Face Spaces:** For hosting the final application.
* **Scikit-learn:** For K-Fold cross-validation and metrics.
* **NumPy** & **Pillow:** For data manipulation and image processing.
* **Albumentations:** For data augmentation.

---

## ⚙️ Setup and Local Usage

To run this project on your local machine, follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/muanderson/Handwritten-digit-and-letter-recogniser
    cd Handwritten-digit-and-letter-recogniser
    ```

2.  **Create and activate the Conda environment:**
    ```bash
    conda create --name ENVIRONMENT_NAME python=3.9
    conda activate ENVIRONMENT_NAME
    ```

3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Run the MLflow UI:** Open a separate terminal, activate the environment, and run:
    ```bash
    mlflow ui
    ```
    You can view the tracking server at `http://localhost:5000`.

5.  **Run the training and fine-tuning scripts:**
    ```bash
    # Train the base model on MNIST
    python train_with_mlflow.py

6.  **Run the prediction app:**
    ```bash
    # Make sure you have the final model saved
    python interact.py
    ```
    The application will be available at `http://127.0.0.1:5000` (or the port specified in the script).
